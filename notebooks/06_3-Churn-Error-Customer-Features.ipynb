{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise: identificando pontos de melhoria no modelo\n",
    "Tentando descobrir onde o modelo possui mais incerteza para identificar padrões de Churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils.DataTransformer import DataTransformer\n",
    "from Utils.DuckDb.DuckDb import DuckDb\n",
    "from Utils.DatasetProcessor.DatasetProcessorUtils import DatasetProcessorUtils\n",
    "from Utils.DataAnalysis import DataAnalysis\n",
    "import pandas as pd\n",
    "from Utils import PandasNotebookConfigs\n",
    "import project_config\n",
    "import matplotlib.pyplot as plt\n",
    "from Utils.Datetime import DatetimeUtils\n",
    "from Utils.Dict import DictUtils\n",
    "from Utils.Number import NumberUtils\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ajustando display.float.format para %.4f\n",
      "Ajustando prints de linhas e colunas\n"
     ]
    }
   ],
   "source": [
    "PandasNotebookConfigs.config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "DUCK_DB = DuckDb()\n",
    "DATA_TRANSFORMER = DataTransformer()\n",
    "DATA_PROCESSOR_UTILS = DatasetProcessorUtils(DUCK_DB)\n",
    "DATETIME_UTILS = DatetimeUtils()\n",
    "DICT_UTILS = DictUtils()\n",
    "DATA_ANALYSIS = DataAnalysis()\n",
    "NUMBER_UTILS = NumberUtils()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0a5550c723346a9a97a9d15af1fcb0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = DUCK_DB.load_table(\n",
    "    project_config.PREDICTED_DATA_TABLE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test filtering\n",
    "# df = df[df['no_churn_information'] == False]\n",
    "# df = df[:10_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['uncertainty'] = df.apply(\n",
    "    lambda row: min(row['predicted_is_churn_proba_true'], row['predicted_is_churn_proba_false']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "features = df[['predicted_is_churn_proba_true', 'uncertainty']]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the optimal cluster qty\n",
    "elbow_scores = []\n",
    "sil_scores = []\n",
    "cluster_range = range(2, 8)  # Testa de 2 até 7 clusters\n",
    "\n",
    "for k in cluster_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(scaled_features)\n",
    "    elbow_scores.append(kmeans.inertia_)\n",
    "    sil = silhouette_score(scaled_features, kmeans.labels_)\n",
    "    sil_scores.append(sil)\n",
    "    \n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(cluster_range, elbow_scores, marker='o')\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Número de Clusters')\n",
    "plt.ylabel('Inércia (Soma dos quadrados intra-cluster)')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(cluster_range, sil_scores, marker='o', color='orange')\n",
    "plt.title('Silhouette Score')\n",
    "plt.xlabel('Número de Clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_k = 3\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "df['cluster'] = kmeans.fit_predict(scaled_features)\n",
    "\n",
    "cluster_summary = df.groupby('cluster')[['predicted_is_churn_proba_true', 'uncertainty']].mean()\n",
    "print(\"\\nResumo dos clusters:\")\n",
    "print(cluster_summary)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(\n",
    "    data=df,\n",
    "    x='predicted_is_churn_proba_true',\n",
    "    y='uncertainty',\n",
    "    hue='cluster',\n",
    "    palette='viridis',\n",
    "    s=100,\n",
    "    alpha=0.7\n",
    ")\n",
    "plt.title(\"Clusters: Probabilidade de Churn vs. Incerteza\")\n",
    "plt.xlabel(\"Probabilidade Predita para Churn (True)\")\n",
    "plt.ylabel(\"Incerteza (min(prob_true, prob_false))\")\n",
    "plt.show()\n",
    "\n",
    "# Exibindo a contagem de clientes em cada cluster\n",
    "cluster_counts = df['cluster'].value_counts()\n",
    "print(\"\\nContagem de clientes por cluster:\")\n",
    "print(cluster_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_uncertainty = df.groupby('cluster')['uncertainty'].mean().sort_values(ascending=False)\n",
    "uncertain_cluster = cluster_uncertainty.index[0]\n",
    "print(f\"Cluster com maior incerteza: {uncertain_cluster}\")\n",
    "\n",
    "df_uncertain = df[df['cluster'] == uncertain_cluster]\n",
    "df_rest = df[df['cluster'] != uncertain_cluster]\n",
    "\n",
    "features_to_analyze = [\n",
    "    'is_auto_renew', 'is_cancel', 'remaining_days',\n",
    "\n",
    "    # Historical Data\n",
    "    'num_100', 'num_100-1M', 'num_100-2M',\n",
    "    'num_25', 'num_25-1M', 'num_25-2M',\n",
    "    'num_50', 'num_50-1M', 'num_50-2M',\n",
    "    'num_75', 'num_75-1M', 'num_75-2M',\n",
    "    'num_985', 'num_985-1M', 'num_985-2M',\n",
    "    'num_unq', 'num_unq-1M', 'num_unq-2M',\n",
    "    'total_secs', 'total_secs-1M', 'total_secs-2M',\n",
    "\n",
    "    # Categorical Data\n",
    "    'city_0', 'city_1', 'city_10', 'city_11', 'city_12', 'city_13', 'city_14', 'city_15', 'city_16', 'city_17', 'city_18', 'city_19', 'city_2', 'city_20', 'city_21', 'city_22', 'city_3', 'city_4', 'city_5', 'city_6', 'city_7', 'city_8', 'city_9',\n",
    "\n",
    "    'registered_via_0', 'registered_via_1', 'registered_via_10', 'registered_via_11', 'registered_via_12', 'registered_via_13', 'registered_via_14', 'registered_via_15', 'registered_via_16', 'registered_via_17', 'registered_via_18', 'registered_via_19', 'registered_via_2', 'registered_via_3', 'registered_via_4', 'registered_via_5', 'registered_via_6', 'registered_via_7', 'registered_via_8', 'registered_via_9',\n",
    "\n",
    "    'payment_method_id_0', 'payment_method_id_1', 'payment_method_id_10', 'payment_method_id_11', 'payment_method_id_12', 'payment_method_id_13', 'payment_method_id_14', 'payment_method_id_15', 'payment_method_id_16', 'payment_method_id_17', 'payment_method_id_18', 'payment_method_id_19', 'payment_method_id_2', 'payment_method_id_20', 'payment_method_id_21', 'payment_method_id_22', 'payment_method_id_23', 'payment_method_id_24', 'payment_method_id_25', 'payment_method_id_26', 'payment_method_id_27', 'payment_method_id_28', 'payment_method_id_29', 'payment_method_id_3', 'payment_method_id_30', 'payment_method_id_31', 'payment_method_id_32', 'payment_method_id_33', 'payment_method_id_34', 'payment_method_id_35', 'payment_method_id_36', 'payment_method_id_37', 'payment_method_id_38', 'payment_method_id_39', 'payment_method_id_4', 'payment_method_id_40', 'payment_method_id_41', 'payment_method_id_5', 'payment_method_id_6', 'payment_method_id_7', 'payment_method_id_8', 'payment_method_id_9',\n",
    "]\n",
    "\n",
    "# Filter only valid features\n",
    "features_to_analyze = [\n",
    "    f for f in features_to_analyze if df_uncertain[f].var() != 0 and df_rest[f].var() != 0\n",
    "]\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    math.ceil(len(features_to_analyze) / 2), 2,\n",
    "    figsize=(16, len(features_to_analyze) * 3)\n",
    ")\n",
    "\n",
    "axs = axs.flatten()\n",
    "\n",
    "for index, feature in enumerate(features_to_analyze):\n",
    "    sns.kdeplot(\n",
    "        df_uncertain[feature],\n",
    "        label='Cluster de alta incerteza',\n",
    "        fill=True,\n",
    "        warn_singular=False,\n",
    "        ax=axs[index]\n",
    "    )\n",
    "\n",
    "    sns.kdeplot(\n",
    "        df_rest[feature],\n",
    "        label='Outros clusters',\n",
    "        fill=True,\n",
    "        warn_singular=False,\n",
    "        ax=axs[index]\n",
    "    )\n",
    "\n",
    "    axs[index].set_title(f'Distribuição de {feature}')\n",
    "    axs[index].set_label(feature)\n",
    "    axs[index].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_uncertain = df_uncertain[features_to_analyze].describe()\n",
    "desc_rest = df_rest[features_to_analyze].describe()\n",
    "\n",
    "print(\"Estatísticas para o cluster com alta incerteza:\")\n",
    "print(desc_uncertain)\n",
    "print(\"\\nEstatísticas para os demais clusters:\")\n",
    "print(desc_rest)\n",
    "\n",
    "corr_features = features_to_analyze + ['uncertainty']\n",
    "corr_matrix = df[corr_features].corr()['uncertainty']\n",
    "\n",
    "print(\"\\nCorrelação entre as features e 'uncertainty':\")\n",
    "print(corr_matrix)\n",
    "\n",
    "plt.figure(figsize=(8, 40))\n",
    "\n",
    "# sns.barplot(x=corr_matrix.values, y=corr_matrix.index, palette='coolwarm')\n",
    "# plt.title(\"Correlation with Column1\")\n",
    "# plt.xlabel(\"Correlation Coefficient\")\n",
    "# plt.ylabel(\"Columns\")\n",
    "# plt.show()\n",
    "\n",
    "ax = sns.barplot(x=corr_matrix.values, y=corr_matrix.index, palette='coolwarm')\n",
    "\n",
    "# Add the correlation values next to the bars\n",
    "for i, value in enumerate(corr_matrix.values):\n",
    "    ax.text(value + 0.02, i, f\"{value:.2f}\", color='black', va='center')  # Adjust text position slightly\n",
    "\n",
    "# Final touches to the plot\n",
    "plt.title(\"Correlation with Column1\")\n",
    "plt.xlabel(\"Correlation Coefficient\")\n",
    "plt.ylabel(\"Columns\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
